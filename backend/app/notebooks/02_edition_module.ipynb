{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0918174c",
   "metadata": {},
   "source": [
    "# 02. Módulo de Edición (Código Fuente Incluido)\n",
    "\n",
    "Este notebook implementa el sistema de anonimización de video. Contiene la lógica para aplicar efectos visuales (blur, pixelado, máscaras, etc.) sobre regiones específicas del video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b8c94",
   "metadata": {},
   "source": [
    "### 1. Imports y Configuración\n",
    "Importamos `opencv` (cv2) para manipulación de imágenes/video y `numpy` para operaciones matriciales (los efectos suelen ser manipulaciones de matrices de píxeles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9749703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Kornia para efectos GPU\n",
    "try:\n",
    "    import kornia\n",
    "    import kornia.filters\n",
    "    KORNIA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Kornia no instalado. Ejecuta: pip install kornia>=0.7.0\")\n",
    "    print(\"Los efectos se ejecutarán en CPU con OpenCV.\")\n",
    "    KORNIA_AVAILABLE = False\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3604cf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:KorniaEffects initialized on cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Kornia disponible: True\n",
      "✓ Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# KORNIA EFFECTS - Efectos acelerados por GPU\n",
    "# =============================================================================\n",
    "class KorniaEffects:\n",
    "    \"\"\"\n",
    "    Efectos de anonimización acelerados por GPU usando Kornia + PyTorch.\n",
    "    \n",
    "    Arquitectura híbrida:\n",
    "    - OpenCV: Video I/O (lectura/escritura)\n",
    "    - Kornia/PyTorch: Efectos en GPU (blur, pixelate)\n",
    "    \n",
    "    Rendimiento esperado vs OpenCV CPU:\n",
    "    - Blur: ~5-7x más rápido\n",
    "    - Pixelate: ~3-5x más rápido\n",
    "    \n",
    "    Uso:\n",
    "        effects = KorniaEffects()\n",
    "        tensor = effects.numpy_to_tensor(frame)  # [B, C, H, W]\n",
    "        blurred = effects.blur_regions(tensor, bboxes)\n",
    "        result = effects.tensor_to_numpy(blurred)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, device: str = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            device: \"cuda\" o \"cpu\". Si None, auto-detecta.\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        # Cache de tensores de ruido para consistencia entre frames\n",
    "        self.noise_cache: Dict[Tuple[int, int, int], torch.Tensor] = {}\n",
    "        \n",
    "        logger.info(f\"KorniaEffects initialized on {self.device}\")\n",
    "        \n",
    "        if self.device == \"cuda\" and not KORNIA_AVAILABLE:\n",
    "            logger.warning(\"Kornia not available, falling back to CPU OpenCV\")\n",
    "    \n",
    "    def numpy_to_tensor(self, frame: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Convierte frame numpy (H, W, C) BGR a tensor (1, C, H, W) RGB en GPU.\n",
    "        \"\"\"\n",
    "        # BGR -> RGB\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # (H, W, C) -> (C, H, W) -> (1, C, H, W)\n",
    "        tensor = torch.from_numpy(rgb).permute(2, 0, 1).unsqueeze(0)\n",
    "        \n",
    "        # Normalizar a [0, 1] y mover a device\n",
    "        tensor = tensor.float().div(255.0).to(self.device)\n",
    "        \n",
    "        return tensor\n",
    "    \n",
    "    def tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convierte tensor (1, C, H, W) RGB a numpy (H, W, C) BGR.\n",
    "        \"\"\"\n",
    "        # (1, C, H, W) -> (C, H, W) -> (H, W, C)\n",
    "        arr = tensor.squeeze(0).permute(1, 2, 0)\n",
    "        \n",
    "        # Desnormalizar y convertir a uint8\n",
    "        arr = arr.mul(255.0).clamp(0, 255).byte()\n",
    "        \n",
    "        # Mover a CPU y convertir a numpy\n",
    "        arr = arr.cpu().numpy()\n",
    "        \n",
    "        # RGB -> BGR\n",
    "        return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    def blur_region(\n",
    "        self, \n",
    "        tensor: torch.Tensor, \n",
    "        bbox: Tuple[int, int, int, int],\n",
    "        kernel_size: int = 31,\n",
    "        sigma: float = 15.0\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Aplica Gaussian blur GPU a una región del tensor.\n",
    "        \n",
    "        Args:\n",
    "            tensor: Tensor (1, C, H, W)\n",
    "            bbox: (x1, y1, x2, y2)\n",
    "            kernel_size: Tamaño del kernel (debe ser impar)\n",
    "            sigma: Desviación estándar del blur\n",
    "            \n",
    "        Returns:\n",
    "            Tensor con región blurreada\n",
    "        \"\"\"\n",
    "        if not KORNIA_AVAILABLE:\n",
    "            # Fallback a CPU OpenCV\n",
    "            return self._blur_opencv_fallback(tensor, bbox, kernel_size, sigma)\n",
    "        \n",
    "        x1, y1, x2, y2 = bbox\n",
    "        result = tensor.clone()\n",
    "        \n",
    "        # Extraer ROI\n",
    "        roi = tensor[:, :, y1:y2, x1:x2]\n",
    "        \n",
    "        # Asegurar kernel impar\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        \n",
    "        # Aplicar blur con Kornia\n",
    "        blurred_roi = kornia.filters.gaussian_blur2d(\n",
    "            roi, \n",
    "            (kernel_size, kernel_size), \n",
    "            (sigma, sigma)\n",
    "        )\n",
    "        \n",
    "        # Insertar ROI blurreado\n",
    "        result[:, :, y1:y2, x1:x2] = blurred_roi\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _blur_opencv_fallback(\n",
    "        self, \n",
    "        tensor: torch.Tensor, \n",
    "        bbox: Tuple[int, int, int, int],\n",
    "        kernel_size: int,\n",
    "        sigma: float\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Fallback blur usando OpenCV CPU\"\"\"\n",
    "        frame = self.tensor_to_numpy(tensor)\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        \n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        k = kernel_size | 1  # Asegurar impar\n",
    "        blurred = cv2.GaussianBlur(roi, (k, k), sigma)\n",
    "        frame[y1:y2, x1:x2] = blurred\n",
    "        \n",
    "        return self.numpy_to_tensor(frame)\n",
    "    \n",
    "    def pixelate_region(\n",
    "        self, \n",
    "        tensor: torch.Tensor, \n",
    "        bbox: Tuple[int, int, int, int],\n",
    "        blocks: int = 10,\n",
    "        track_id: int = 0,\n",
    "        add_noise: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Aplica pixelado GPU a una región del tensor.\n",
    "        \n",
    "        Usa F.interpolate para downscale/upscale, que es muy eficiente en GPU.\n",
    "        Opcionalmente añade ruido consistente (mismo ruido para mismo track_id).\n",
    "        \n",
    "        Args:\n",
    "            tensor: Tensor (1, C, H, W)\n",
    "            bbox: (x1, y1, x2, y2)\n",
    "            blocks: Número de bloques de pixelado\n",
    "            track_id: ID para cache de ruido consistente\n",
    "            add_noise: Añadir ruido para mejor anonimización\n",
    "            \n",
    "        Returns:\n",
    "            Tensor con región pixelada\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        result = tensor.clone()\n",
    "        \n",
    "        # Extraer ROI\n",
    "        roi = tensor[:, :, y1:y2, x1:x2]\n",
    "        orig_h, orig_w = roi.shape[2], roi.shape[3]\n",
    "        \n",
    "        if orig_h < 2 or orig_w < 2:\n",
    "            return result\n",
    "        \n",
    "        # Downscale a bloques\n",
    "        small = F.interpolate(\n",
    "            roi, \n",
    "            size=(blocks, blocks), \n",
    "            mode='bilinear', \n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        # Añadir ruido consistente si se solicita\n",
    "        if add_noise:\n",
    "            cache_key = (track_id, blocks, 3)  # 3 canales\n",
    "            \n",
    "            if cache_key not in self.noise_cache:\n",
    "                # Generar ruido determinístico basado en track_id\n",
    "                gen = torch.Generator(device=self.device)\n",
    "                gen.manual_seed(track_id * 1000 + blocks)\n",
    "                \n",
    "                noise = torch.rand(\n",
    "                    1, 3, blocks, blocks, \n",
    "                    generator=gen, \n",
    "                    device=self.device\n",
    "                ) * 0.2 - 0.1  # Ruido en rango [-0.1, 0.1]\n",
    "                \n",
    "                self.noise_cache[cache_key] = noise\n",
    "            \n",
    "            small = small + self.noise_cache[cache_key]\n",
    "            small = small.clamp(0, 1)\n",
    "        \n",
    "        # Upscale con nearest neighbor (mantiene bloques)\n",
    "        pixelated = F.interpolate(\n",
    "            small, \n",
    "            size=(orig_h, orig_w), \n",
    "            mode='nearest'\n",
    "        )\n",
    "        \n",
    "        # Insertar ROI pixelado\n",
    "        result[:, :, y1:y2, x1:x2] = pixelated\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def blur_regions_batch(\n",
    "        self, \n",
    "        tensor: torch.Tensor, \n",
    "        bboxes: List[Tuple[int, int, int, int]],\n",
    "        kernel_size: int = 31,\n",
    "        sigma: float = 15.0\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Aplica blur a múltiples regiones\"\"\"\n",
    "        result = tensor.clone()\n",
    "        for bbox in bboxes:\n",
    "            result = self.blur_region(result, bbox, kernel_size, sigma)\n",
    "        return result\n",
    "    \n",
    "    def pixelate_regions_batch(\n",
    "        self,\n",
    "        tensor: torch.Tensor,\n",
    "        regions: List[Dict],  # [{\"bbox\": (x1,y1,x2,y2), \"track_id\": id, \"blocks\": n}, ...]\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Aplica pixelado a múltiples regiones con configuración individual\"\"\"\n",
    "        result = tensor.clone()\n",
    "        for region in regions:\n",
    "            result = self.pixelate_region(\n",
    "                result,\n",
    "                bbox=region[\"bbox\"],\n",
    "                blocks=region.get(\"blocks\", 10),\n",
    "                track_id=region.get(\"track_id\", 0),\n",
    "                add_noise=region.get(\"add_noise\", True)\n",
    "            )\n",
    "        return result\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"Limpia cache de ruido\"\"\"\n",
    "        self.noise_cache.clear()\n",
    "        if self.device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "# Instancia global para reutilización\n",
    "kornia_effects = KorniaEffects() if KORNIA_AVAILABLE or torch.cuda.is_available() else None\n",
    "\n",
    "print(f\"✓ Kornia disponible: {KORNIA_AVAILABLE}\")\n",
    "print(f\"✓ Device: {kornia_effects.device if kornia_effects else 'CPU (OpenCV only)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc711e",
   "metadata": {},
   "source": [
    "### 2. Video Anonymizer (`video_editor.py`)\n",
    "Esta es la clase principal que procesa el video.\n",
    "\n",
    "- **`apply_anonymization`**: \n",
    "    - Abre el video de entrada y crea un escritor (`VideoWriter`) para la salida.\n",
    "    - Lee frames uno a uno.\n",
    "    - Llama a `_process_frame` para aplicar efectos en cada frame.\n",
    "    - Guarda el resultado.\n",
    "\n",
    "- **`_process_frame`**: \n",
    "    - Recorre la lista de `actions`. Cada acción define qué efecto aplicar y en qué frames/coordenadas (`bboxes`).\n",
    "    - Si el frame actual tiene una caja definida en las acciones, llama a `_apply_effect`.\n",
    "\n",
    "- **`_apply_effect`**: La lógica visual real:\n",
    "    - **`blur`**: Aplica un difuminado Gaussiano. Útil para privacidad suave.\n",
    "    - **`pixelate`** (con ruido): Reduce la imagen a bloques y añade ruido aleatorio antes de re-escalar. Esto impide que se reconozcan rasgos incluso con bloques pequeños.\n",
    "    - **`mask`**: Mezcla los píxeles usando una clave secreta. Es reversible si se conoce la clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659ee0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoAnonymizer:\n",
    "    \"\"\"\n",
    "    Anonimizador de video con aceleración GPU (Kornia) y fallback CPU (OpenCV).\n",
    "    \n",
    "    Arquitectura híbrida:\n",
    "    - OpenCV: Video I/O (VideoCapture/VideoWriter)\n",
    "    - Kornia + PyTorch: Efectos en GPU (blur, pixelate) cuando está disponible\n",
    "    - OpenCV: Efectos en CPU como fallback\n",
    "    \n",
    "    Mejoras incluidas:\n",
    "    - Cache de ruido para evitar flickering en pixelado\n",
    "    - Interpolación de bboxes para suavizar movimiento\n",
    "    - Procesamiento por batches para eficiencia GPU\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_gpu: bool = True, batch_frames: int = 8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            use_gpu: Intentar usar GPU si está disponible\n",
    "            batch_frames: Número de frames a procesar en batch (GPU)\n",
    "        \"\"\"\n",
    "        self.use_gpu = use_gpu and (KORNIA_AVAILABLE or torch.cuda.is_available())\n",
    "        self.batch_frames = batch_frames\n",
    "        \n",
    "        # Instancia de efectos Kornia\n",
    "        self.kornia = kornia_effects if self.use_gpu else None\n",
    "        \n",
    "        # Cache de ruido para CPU fallback\n",
    "        self.noise_cache = {}\n",
    "        \n",
    "        logger.info(f\"VideoAnonymizer: GPU={self.use_gpu}, batch={batch_frames}\")\n",
    "\n",
    "    def _interpolate_bboxes(self, actions: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Rellena frames faltantes con interpolación lineal.\n",
    "        Evita saltos bruscos cuando hay gaps en la detección.\n",
    "        \"\"\"\n",
    "        for action in actions:\n",
    "            bboxes = action.get(\"bboxes\", {})\n",
    "            if not bboxes:\n",
    "                continue\n",
    "                \n",
    "            frames = sorted(bboxes.keys())\n",
    "            if len(frames) < 2:\n",
    "                continue\n",
    "            \n",
    "            interpolated = dict(bboxes)\n",
    "            \n",
    "            for i in range(len(frames) - 1):\n",
    "                f1, f2 = frames[i], frames[i + 1]\n",
    "                gap = f2 - f1\n",
    "                \n",
    "                # Solo interpolar si hay gap pequeño (< 10 frames)\n",
    "                if 1 < gap <= 10:\n",
    "                    b1 = bboxes[f1]\n",
    "                    b2 = bboxes[f2]\n",
    "                    \n",
    "                    for f in range(f1 + 1, f2):\n",
    "                        t = (f - f1) / gap\n",
    "                        interpolated[f] = [\n",
    "                            int(b1[0] + t * (b2[0] - b1[0])),\n",
    "                            int(b1[1] + t * (b2[1] - b1[1])),\n",
    "                            int(b1[2] + t * (b2[2] - b1[2])),\n",
    "                            int(b1[3] + t * (b2[3] - b1[3])),\n",
    "                        ]\n",
    "            \n",
    "            action[\"bboxes\"] = interpolated\n",
    "        \n",
    "        return actions\n",
    "\n",
    "    async def apply_anonymization(\n",
    "        self,\n",
    "        input_path: str,\n",
    "        output_path: str,\n",
    "        actions: List[Dict[str, Any]],\n",
    "        on_progress: Optional[Any] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Aplica anonimización al video.\n",
    "        \n",
    "        Args:\n",
    "            input_path: Ruta del video de entrada\n",
    "            output_path: Ruta del video de salida\n",
    "            actions: Lista de acciones de anonimización\n",
    "            on_progress: Callback de progreso (frame, total, msg)\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        logger.info(f\"Anonymizing video: {input_path} -> {output_path}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            raise ValueError(f\"Failed to open video: {input_path}\")\n",
    "\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        # Interpolar bboxes para suavizar movimiento\n",
    "        actions = self._interpolate_bboxes(actions)\n",
    "        \n",
    "        # Limpiar caches\n",
    "        self.noise_cache = {}\n",
    "        if self.kornia:\n",
    "            self.kornia.clear_cache()\n",
    "        \n",
    "        frame_idx = 0\n",
    "        \n",
    "        try:\n",
    "            if self.use_gpu and self.kornia:\n",
    "                # Procesamiento GPU por batches\n",
    "                await self._process_gpu_batched(\n",
    "                    cap, out, actions, total_frames, on_progress\n",
    "                )\n",
    "            else:\n",
    "                # Procesamiento CPU frame por frame\n",
    "                await self._process_cpu(\n",
    "                    cap, out, actions, total_frames, on_progress\n",
    "                )\n",
    "        finally:\n",
    "            cap.release()\n",
    "            out.release()\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        fps_proc = total_frames / elapsed if elapsed > 0 else 0\n",
    "        logger.info(f\"Anonymization completed: {elapsed:.2f}s ({fps_proc:.1f} fps)\")\n",
    "\n",
    "    async def _process_gpu_batched(\n",
    "        self, \n",
    "        cap, \n",
    "        out, \n",
    "        actions: List[Dict],\n",
    "        total_frames: int,\n",
    "        on_progress\n",
    "    ):\n",
    "        \"\"\"Procesa video en batches usando GPU (Kornia)\"\"\"\n",
    "        frame_buffer = []\n",
    "        frame_indices = []\n",
    "        frame_idx = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                # Procesar batch final\n",
    "                if frame_buffer:\n",
    "                    await self._process_batch_gpu(\n",
    "                        frame_buffer, frame_indices, actions, out\n",
    "                    )\n",
    "                break\n",
    "            \n",
    "            frame_idx += 1\n",
    "            frame_buffer.append(frame)\n",
    "            frame_indices.append(frame_idx)\n",
    "            \n",
    "            if len(frame_buffer) >= self.batch_frames:\n",
    "                await self._process_batch_gpu(\n",
    "                    frame_buffer, frame_indices, actions, out\n",
    "                )\n",
    "                frame_buffer = []\n",
    "                frame_indices = []\n",
    "                \n",
    "                if frame_idx % 20 == 0 and on_progress:\n",
    "                    msg = f\"Frame {frame_idx}/{total_frames}\"\n",
    "                    if asyncio.iscoroutinefunction(on_progress):\n",
    "                        await on_progress(frame_idx, total_frames, msg)\n",
    "                    else:\n",
    "                        on_progress(frame_idx, total_frames, msg)\n",
    "\n",
    "    async def _process_batch_gpu(\n",
    "        self, \n",
    "        frames: List[np.ndarray], \n",
    "        frame_indices: List[int],\n",
    "        actions: List[Dict],\n",
    "        out\n",
    "    ):\n",
    "        \"\"\"Procesa un batch de frames en GPU\"\"\"\n",
    "        for frame, frame_idx in zip(frames, frame_indices):\n",
    "            # Convertir a tensor GPU\n",
    "            tensor = self.kornia.numpy_to_tensor(frame)\n",
    "            \n",
    "            # Recopilar acciones para este frame\n",
    "            blur_regions = []\n",
    "            pixelate_regions = []\n",
    "            mask_regions = []\n",
    "            \n",
    "            for action in actions:\n",
    "                bboxes_map = action.get(\"bboxes\", {})\n",
    "                action_type = action.get(\"type\", \"blur\")\n",
    "                config = action.get(\"config\", {})\n",
    "                track_id = action.get(\"track_id\", 0)\n",
    "                \n",
    "                box = bboxes_map.get(frame_idx)\n",
    "                if not box:\n",
    "                    continue\n",
    "                \n",
    "                bbox = (int(box[0]), int(box[1]), int(box[2]), int(box[3]))\n",
    "                \n",
    "                if action_type == \"blur\":\n",
    "                    blur_regions.append({\n",
    "                        \"bbox\": bbox,\n",
    "                        \"kernel_size\": config.get(\"kernel_size\", 31),\n",
    "                        \"sigma\": config.get(\"sigma\", 15.0)\n",
    "                    })\n",
    "                elif action_type == \"pixelate\":\n",
    "                    pixelate_regions.append({\n",
    "                        \"bbox\": bbox,\n",
    "                        \"blocks\": config.get(\"blocks\", 10),\n",
    "                        \"track_id\": track_id,\n",
    "                        \"add_noise\": config.get(\"add_noise\", True)\n",
    "                    })\n",
    "                elif action_type == \"mask\":\n",
    "                    mask_regions.append({\n",
    "                        \"bbox\": bbox,\n",
    "                        \"key\": config.get(\"key\", 42)\n",
    "                    })\n",
    "            \n",
    "            # Aplicar efectos GPU\n",
    "            for region in blur_regions:\n",
    "                tensor = self.kornia.blur_region(\n",
    "                    tensor, \n",
    "                    region[\"bbox\"],\n",
    "                    region[\"kernel_size\"],\n",
    "                    region[\"sigma\"]\n",
    "                )\n",
    "            \n",
    "            for region in pixelate_regions:\n",
    "                tensor = self.kornia.pixelate_region(\n",
    "                    tensor,\n",
    "                    region[\"bbox\"],\n",
    "                    region[\"blocks\"],\n",
    "                    region[\"track_id\"],\n",
    "                    region[\"add_noise\"]\n",
    "                )\n",
    "            \n",
    "            # Convertir de vuelta a numpy\n",
    "            result_frame = self.kornia.tensor_to_numpy(tensor)\n",
    "            \n",
    "            # Aplicar mask en CPU (requiere permutación compleja)\n",
    "            for region in mask_regions:\n",
    "                self._apply_mask_cpu(result_frame, region[\"bbox\"], region[\"key\"])\n",
    "            \n",
    "            out.write(result_frame)\n",
    "        \n",
    "        await asyncio.sleep(0)\n",
    "\n",
    "    async def _process_cpu(\n",
    "        self, \n",
    "        cap, \n",
    "        out, \n",
    "        actions: List[Dict],\n",
    "        total_frames: int,\n",
    "        on_progress\n",
    "    ):\n",
    "        \"\"\"Procesa video frame por frame en CPU (fallback)\"\"\"\n",
    "        frame_idx = 0\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame_idx += 1\n",
    "            frame = self._process_frame_cpu(frame, frame_idx, actions)\n",
    "            out.write(frame)\n",
    "            \n",
    "            if frame_idx % 20 == 0:\n",
    "                if on_progress:\n",
    "                    msg = f\"Frame {frame_idx}/{total_frames}\"\n",
    "                    if asyncio.iscoroutinefunction(on_progress):\n",
    "                        await on_progress(frame_idx, total_frames, msg)\n",
    "                    else:\n",
    "                        on_progress(frame_idx, total_frames, msg)\n",
    "                await asyncio.sleep(0)\n",
    "\n",
    "    def _process_frame_cpu(self, frame: np.ndarray, frame_idx: int, actions: List[Dict]) -> np.ndarray:\n",
    "        \"\"\"Procesa un frame en CPU (OpenCV)\"\"\"\n",
    "        for action in actions:\n",
    "            bboxes_map = action.get(\"bboxes\", {})\n",
    "            action_type = action.get(\"type\", \"blur\")\n",
    "            config = action.get(\"config\", {})\n",
    "            track_id = action.get(\"track_id\", 0)\n",
    "            \n",
    "            box = bboxes_map.get(frame_idx)\n",
    "            if box:\n",
    "                self._apply_effect_cpu(frame, box, action_type, config, track_id)\n",
    "        return frame\n",
    "\n",
    "    def _apply_effect_cpu(self, frame: np.ndarray, bbox: list, effect: str, config: dict, track_id: int = 0):\n",
    "        \"\"\"Aplica efecto usando OpenCV CPU\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        x1 = max(0, x1); y1 = max(0, y1)\n",
    "        x2 = min(w, x2); y2 = min(h, y2)\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return\n",
    "\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if effect == 'blur':\n",
    "            factor = config.get(\"factor\", 3.0)\n",
    "            k_w = int((x2 - x1) // factor) | 1\n",
    "            k_h = int((y2 - y1) // factor) | 1\n",
    "            blurred = cv2.GaussianBlur(roi, (k_w, k_h), 0)\n",
    "            frame[y1:y2, x1:x2] = blurred\n",
    "            \n",
    "        elif effect == 'pixelate':\n",
    "            blocks = config.get(\"blocks\", 30)\n",
    "            \n",
    "            # Pixelado base\n",
    "            small = cv2.resize(roi, (blocks, blocks), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Ruido consistente por track_id\n",
    "            cache_key = (track_id, blocks)\n",
    "            if cache_key not in self.noise_cache:\n",
    "                rng = np.random.default_rng(seed=track_id * 1000 + blocks)\n",
    "                self.noise_cache[cache_key] = rng.integers(-30, 30, (blocks, blocks, 3), dtype=np.int16)\n",
    "            \n",
    "            noise = self.noise_cache[cache_key]\n",
    "            dirty_small = small.astype(np.int16) + noise\n",
    "            dirty_small = np.clip(dirty_small, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            pixelated = cv2.resize(dirty_small, (x2-x1, y2-y1), interpolation=cv2.INTER_NEAREST)\n",
    "            frame[y1:y2, x1:x2] = pixelated\n",
    "            \n",
    "        elif effect == 'mask':\n",
    "            self._apply_mask_cpu(frame, (x1, y1, x2, y2), config.get(\"key\", 42))\n",
    "\n",
    "    def _apply_mask_cpu(self, frame: np.ndarray, bbox: tuple, key: int):\n",
    "        \"\"\"Aplica efecto mask (scramble) en CPU\"\"\"\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        shape = roi.shape\n",
    "        flat = roi.flatten()\n",
    "        rng = np.random.default_rng(key)\n",
    "        perm = rng.permutation(len(flat))\n",
    "        scrambled = flat[perm]\n",
    "        frame[y1:y2, x1:x2] = scrambled.reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6b728",
   "metadata": {},
   "source": [
    "### 3. Ejecución de Prueba\n",
    "Aquí definimos un escenario ficticio para probar los efectos:\n",
    "- Definimos un objeto que se mueve del frame 1 al 100.\n",
    "- Le aplicamos el nuevo efecto `pixelate` con ruido y 30 bloques.\n",
    "- Ejecutamos el `apply_anonymization` y mostramos el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eddbf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:VideoAnonymizer: GPU=True, batch=8\n",
      "INFO:__main__:Anonymizing video: ../storage/uploads/coche.mp4 -> ../storage/processed/test_kornia_gpu.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BENCHMARK: GPU (Kornia) vs CPU (OpenCV)\n",
      "============================================================\n",
      "\n",
      "[1] Probando GPU (Kornia + PyTorch)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Anonymization completed: 34.45s (54.7 fps)\n",
      "INFO:__main__:VideoAnonymizer: GPU=False, batch=8\n",
      "INFO:__main__:Anonymizing video: ../storage/uploads/coche.mp4 -> ../storage/processed/test_opencv_cpu.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Completado en 34.45s\n",
      "\n",
      "[2] Probando CPU (OpenCV)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Anonymization completed: 1.67s (1128.1 fps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Completado en 1.67s\n",
      "\n",
      "============================================================\n",
      "RESUMEN\n",
      "============================================================\n",
      "  GPU: 34.45s\n",
      "  CPU: 1.67s\n",
      "  Speedup: 0.0x más rápido con GPU\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRUEBA DE EJECUCIÓN\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "VIDEO_PATH = \"../storage/uploads/coche.mp4\" \n",
    "OUTPUT_GPU = \"../storage/processed/test_kornia_gpu.mp4\"\n",
    "OUTPUT_CPU = \"../storage/processed/test_opencv_cpu.mp4\"\n",
    "\n",
    "# Acciones de prueba con diferentes efectos\n",
    "actions = [\n",
    "    {\n",
    "        \"type\": \"blur\",\n",
    "        \"track_id\": 1,\n",
    "        \"config\": {\"kernel_size\": 31, \"sigma\": 15.0},\n",
    "        \"bboxes\": {i: [50, 50, 200, 200] for i in range(1, 100)}\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"pixelate\",\n",
    "        \"track_id\": 2,\n",
    "        \"config\": {\"blocks\": 20, \"add_noise\": True},\n",
    "        \"bboxes\": {i: [250, 50, 450, 250] for i in range(1, 100)}\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"pixelate\",\n",
    "        \"track_id\": 3,\n",
    "        \"config\": {\"blocks\": 10, \"add_noise\": True},\n",
    "        \"bboxes\": {i: [500, 100, 650, 300] for i in range(1, 100)}\n",
    "    }\n",
    "]\n",
    "\n",
    "async def benchmark_anonymizer():\n",
    "    if not os.path.exists(VIDEO_PATH):\n",
    "        print(f\"Video no encontrado: {VIDEO_PATH}\")\n",
    "        print(\"Saltando test. Descarga un video de prueba primero.\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"BENCHMARK: GPU (Kornia) vs CPU (OpenCV)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test GPU (si está disponible)\n",
    "    if kornia_effects is not None:\n",
    "        print(\"\\n[1] Probando GPU (Kornia + PyTorch)...\")\n",
    "        anonymizer_gpu = VideoAnonymizer(use_gpu=True, batch_frames=8)\n",
    "        \n",
    "        start = time.time()\n",
    "        await anonymizer_gpu.apply_anonymization(VIDEO_PATH, OUTPUT_GPU, actions)\n",
    "        gpu_time = time.time() - start\n",
    "        results[\"GPU\"] = gpu_time\n",
    "        \n",
    "        print(f\"    ✓ Completado en {gpu_time:.2f}s\")\n",
    "    else:\n",
    "        print(\"\\n[1] GPU no disponible, saltando...\")\n",
    "    \n",
    "    # Test CPU\n",
    "    print(\"\\n[2] Probando CPU (OpenCV)...\")\n",
    "    anonymizer_cpu = VideoAnonymizer(use_gpu=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    await anonymizer_cpu.apply_anonymization(VIDEO_PATH, OUTPUT_CPU, actions)\n",
    "    cpu_time = time.time() - start\n",
    "    results[\"CPU\"] = cpu_time\n",
    "    \n",
    "    print(f\"    ✓ Completado en {cpu_time:.2f}s\")\n",
    "    \n",
    "    # Resumen\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RESUMEN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if \"GPU\" in results and \"CPU\" in results:\n",
    "        speedup = results[\"CPU\"] / results[\"GPU\"]\n",
    "        print(f\"  GPU: {results['GPU']:.2f}s\")\n",
    "        print(f\"  CPU: {results['CPU']:.2f}s\")\n",
    "        print(f\"  Speedup: {speedup:.1f}x más rápido con GPU\")\n",
    "    elif \"CPU\" in results:\n",
    "        print(f\"  CPU: {results['CPU']:.2f}s\")\n",
    "        print(\"  (GPU no disponible para comparar)\")\n",
    "    \n",
    "    # Mostrar un frame de resultado\n",
    "    if os.path.exists(OUTPUT_GPU):\n",
    "        output_path = OUTPUT_GPU\n",
    "    else:\n",
    "        output_path = OUTPUT_CPU\n",
    "    \n",
    "    cap = cv2.VideoCapture(output_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 50)\n",
    "    ret, img = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(\"Resultado: Blur (izq) + Pixelate 20 bloques (centro) + Pixelate 10 bloques (der)\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        except ImportError:\n",
    "            print(\"\\nMatplotlib no disponible para visualización.\")\n",
    "\n",
    "# Ejecutar benchmark\n",
    "asyncio.run(benchmark_anonymizer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
