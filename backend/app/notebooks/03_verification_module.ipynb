{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6717180b",
   "metadata": {},
   "source": [
    "# 03. MÃ³dulo de VerificaciÃ³n (CÃ³digo Fuente Incluido)\n",
    "\n",
    "Este notebook implementa el sistema de verificaciÃ³n GDPR basado en IA. Combina una base de datos de grafos (Neo4j) para el contexto legal y un LLM (Gemma) para el anÃ¡lisis de imÃ¡genes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c6d97",
   "metadata": {},
   "source": [
    "### 1. ConfiguraciÃ³n Inicial\n",
    "Cargamos variables de entorno (`.env`) para conectar con Neo4j y definimos configuraciones bÃ¡sicas como el modelo de LLM que vamos a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54f9b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "import time  # NUEVO: Para cache TTL\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Cargar environment (ajusta la ruta si hace falta)\n",
    "load_dotenv(os.path.abspath(os.path.join(\"..\", \".env\")))\n",
    "\n",
    "# ConfiguraciÃ³n de cache\n",
    "CACHE_TTL_SECONDS = 300  # 5 minutos\n",
    "\n",
    "# SimulaciÃ³n de GDPRQueries y config\n",
    "class GDPRQueries:\n",
    "    GET_ARTICLES_FOR_DETECTION = \"MATCH (a:GDPRArticle {category: $detection_type}) RETURN a.article_number as article_number, a.title as title, a.content as content\"\n",
    "    SEMANTIC_SEARCH = \"\" # Placeholder\n",
    "    GET_FINE_INFO = \"\"\n",
    "    GET_EXPLANATION_GRAPH = \"\"\n",
    "\n",
    "def get_config():\n",
    "    class Config:\n",
    "        verification = {\"llm_model\": \"google/gemma-3n-E4B-it\"}\n",
    "    return Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df131dcc",
   "metadata": {},
   "source": [
    "### 2. Cliente de Grafo (`graph_client.py`)\n",
    "Maneja la conexiÃ³n a la base de datos de grafos Neo4j.\n",
    "- **`_init_driver`**: Conecta usando las credenciales del `.env`.\n",
    "- **`get_context_for_detection`**: Dado un tipo de detecciÃ³n (ej. \"persona\"), busca en el grafo quÃ© artÃ­culos del GDPR se aplican.\n",
    "    - Si la DB no estÃ¡ disponible, devuelve un mock para que el notebook no falle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60491cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, AsyncGraphDatabase\n",
    "\n",
    "class GraphClient:\n",
    "    \"\"\"\n",
    "    Cliente de grafo mejorado con cache de contexto para evitar queries repetidas.\n",
    "    \"\"\"\n",
    "    _instance = None\n",
    "    \n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(GraphClient, cls).__new__(cls)\n",
    "            cls._instance._init_driver()\n",
    "            cls._instance._context_cache = {}  # NUEVO: Cache de contexto\n",
    "            cls._instance._cache_timestamps = {}  # NUEVO: Timestamps para TTL\n",
    "        return cls._instance\n",
    "    \n",
    "    def _init_driver(self):\n",
    "        uri = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "        user = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "        password = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "        try:\n",
    "            self.driver = AsyncGraphDatabase.driver(uri, auth=(user, password))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to init Neo4j driver: {e}\")\n",
    "            self.driver = None\n",
    "        \n",
    "    async def close(self):\n",
    "        if self.driver:\n",
    "            await self.driver.close()\n",
    "    \n",
    "    def _is_cache_valid(self, key: str) -> bool:\n",
    "        \"\"\"NUEVO: Verifica si el cache sigue siendo vÃ¡lido (TTL)\"\"\"\n",
    "        if key not in self._cache_timestamps:\n",
    "            return False\n",
    "        return (time.time() - self._cache_timestamps[key]) < CACHE_TTL_SECONDS\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"NUEVO: Limpia el cache manualmente si es necesario\"\"\"\n",
    "        self._context_cache = {}\n",
    "        self._cache_timestamps = {}\n",
    "            \n",
    "    async def get_context_for_detection(self, detection_type: str) -> List[Dict[str, Any]]:\n",
    "        # NUEVO: Verificar cache primero\n",
    "        cache_key = f\"context:{detection_type}\"\n",
    "        if cache_key in self._context_cache and self._is_cache_valid(cache_key):\n",
    "            return self._context_cache[cache_key]\n",
    "        \n",
    "        if not self.driver:\n",
    "            # Fallback mock context if DB is not up\n",
    "            result = [{\n",
    "                \"article_number\": \"6\",\n",
    "                \"title\": \"Lawfulness of processing\",\n",
    "                \"content\": \"Processing shall be lawful only if...\"\n",
    "            }]\n",
    "            # Cache el mock tambiÃ©n\n",
    "            self._context_cache[cache_key] = result\n",
    "            self._cache_timestamps[cache_key] = time.time()\n",
    "            return result\n",
    "            \n",
    "        try:\n",
    "            async with self.driver.session() as session:\n",
    "                result = await session.run(\n",
    "                    GDPRQueries.GET_ARTICLES_FOR_DETECTION,\n",
    "                    {\"detection_type\": detection_type}\n",
    "                )\n",
    "                records = await result.data()\n",
    "                \n",
    "                # NUEVO: Guardar en cache\n",
    "                self._context_cache[cache_key] = records\n",
    "                self._cache_timestamps[cache_key] = time.time()\n",
    "                \n",
    "                return records\n",
    "        except Exception as e:\n",
    "            print(f\"Neo4j Error: {e}\")\n",
    "            return []\n",
    "\n",
    "    async def semantic_search(self, *args, **kwargs): \n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe593af",
   "metadata": {},
   "source": [
    "### 3. Cliente LLM (`gemma_client.py`)\n",
    "Interfaz con el modelo de lenguaje (Gemma).\n",
    "- **`analyze_image`**: RecibirÃ­a la imagen y el contexto legal, y preguntarÃ­a al LLM si hay violaciÃ³n de privacidad.\n",
    "- **`_mock_response`**: En este notebook usamos un mock para no depender de tener el modelo de 4GB cargado en memoria local, simulando que detecta una violaciÃ³n si es \"face\" o \"license_plate\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd4283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Severidad GDPR por tipo de dato\n",
    "GDPR_SEVERITY_MAP = {\n",
    "    \"face\": \"high\",           # Dato biomÃ©trico - Art. 9 GDPR\n",
    "    \"fingerprint\": \"high\",    # Dato biomÃ©trico - Art. 9 GDPR\n",
    "    \"license_plate\": \"high\",  # Identificador personal indirecto\n",
    "    \"id_document\": \"high\",    # Documento oficial\n",
    "    \"credit_card\": \"high\",    # Dato financiero\n",
    "    \"signature\": \"medium\",    # Identificador personal\n",
    "    \"person\": \"medium\",       # Imagen personal\n",
    "}\n",
    "\n",
    "# ArtÃ­culos GDPR relacionados por tipo\n",
    "GDPR_ARTICLES = {\n",
    "    \"face\": [\"9\", \"6\"],           # Datos biomÃ©tricos + Base legal\n",
    "    \"fingerprint\": [\"9\", \"6\"],\n",
    "    \"license_plate\": [\"6\", \"17\"], # Base legal + Derecho al olvido\n",
    "    \"person\": [\"6\", \"13\"],        # Base legal + InformaciÃ³n\n",
    "    \"id_document\": [\"9\", \"6\", \"32\"],  # Especial + Seguridad\n",
    "    \"credit_card\": [\"6\", \"32\"],   # Base legal + Seguridad\n",
    "    \"signature\": [\"6\"],\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PROMPTS PARA CLASIFICACIÃ“N DE CONTENIDO SENSIBLE\n",
    "# =============================================================================\n",
    "\n",
    "SENSITIVE_CONTENT_CLASSIFICATION_PROMPT = \"\"\"\n",
    "Analyze this image crop and determine if it contains any of the following sensitive content:\n",
    "\n",
    "1. **Fingerprint**: A finger showing visible ridge patterns (the lines/whorls on fingertips)\n",
    "2. **ID Document**: Any official identification document (passport, national ID, driver's license, residence permit)\n",
    "3. **Credit Card**: A bank card, credit card, or debit card showing numbers or chip\n",
    "4. **Signature**: A handwritten signature or autograph\n",
    "5. **Hand with biometric features**: A hand that could be used for palm print recognition\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- A regular hand holding something is NOT a fingerprint unless ridge patterns are clearly visible\n",
    "- A blank card or generic plastic is NOT a credit card unless it has numbers/chip visible\n",
    "- Random text is NOT a signature unless it's clearly a handwritten personal signature\n",
    "\n",
    "Respond with a JSON object:\n",
    "{\n",
    "  \"detected_type\": \"fingerprint|id_document|credit_card|signature|hand_biometric|none\",\n",
    "  \"confidence\": 0.0 to 1.0,\n",
    "  \"reasoning\": \"Brief explanation of why this classification was made\"\n",
    "}\n",
    "\n",
    "If no sensitive content is detected, return:\n",
    "{\n",
    "  \"detected_type\": \"none\",\n",
    "  \"confidence\": 0.9,\n",
    "  \"reasoning\": \"No sensitive personal data detected in this crop\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "GDPR_VIOLATION_ANALYSIS_PROMPT = \"\"\"\n",
    "You are a GDPR compliance expert. Analyze this detection and determine if it constitutes a privacy violation.\n",
    "\n",
    "Detection Type: {detection_type}\n",
    "Legal Context (GDPR Articles):\n",
    "{legal_context}\n",
    "\n",
    "Based on GDPR regulations, determine:\n",
    "1. Is this a privacy violation? (recording/processing without consent)\n",
    "2. What is the severity? (high/medium/low)\n",
    "3. Which specific GDPR articles apply?\n",
    "4. What action should be taken? (blur/pixelate/redact)\n",
    "\n",
    "Respond with JSON:\n",
    "{{\n",
    "  \"is_violation\": true/false,\n",
    "  \"severity\": \"high|medium|low|none\",\n",
    "  \"violated_articles\": [\"6\", \"9\", ...],\n",
    "  \"reasoning\": \"Explanation\",\n",
    "  \"recommended_action\": \"blur|pixelate|redact|none\",\n",
    "  \"confidence\": 0.0 to 1.0\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "class GemmaClient:\n",
    "    \"\"\"\n",
    "    Cliente LLM mejorado con:\n",
    "    - ClasificaciÃ³n de contenido sensible (huellas, documentos, etc.)\n",
    "    - AnÃ¡lisis de violaciones GDPR\n",
    "    - Soporte para procesamiento de imÃ¡genes con visiÃ³n\n",
    "    \"\"\"\n",
    "    _instance = None\n",
    "    \n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(GemmaClient, cls).__new__(cls)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        if hasattr(self, 'config'):\n",
    "            return\n",
    "        self.config = get_config()\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = None  # Se carga bajo demanda\n",
    "        self.processor = None\n",
    "        \n",
    "        # Cache de clasificaciones para evitar re-procesar\n",
    "        self._classification_cache = {}\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Carga el modelo LLM bajo demanda\"\"\"\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "            model_name = self.config.verification.llm_model\n",
    "            \n",
    "            logging.info(f\"Loading LLM model: {model_name}\")\n",
    "            self.processor = AutoProcessor.from_pretrained(model_name)\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "                device_map=\"auto\" if self.device == \"cuda\" else None\n",
    "            )\n",
    "            logging.info(\"LLM model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not load LLM model: {e}. Using mock responses.\")\n",
    "            self.model = \"mock\"\n",
    "    \n",
    "    async def classify_sensitive_content(\n",
    "        self, \n",
    "        image_path: str,\n",
    "        use_cache: bool = True\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Clasifica si una imagen contiene contenido sensible no detectable por YOLO.\n",
    "        \n",
    "        Tipos detectables:\n",
    "        - fingerprint: Huellas dactilares visibles\n",
    "        - id_document: Documentos de identidad (DNI, pasaporte, etc.)\n",
    "        - credit_card: Tarjetas de crÃ©dito/dÃ©bito\n",
    "        - signature: Firmas manuscritas\n",
    "        - hand_biometric: Manos con caracterÃ­sticas biomÃ©tricas visibles\n",
    "        \n",
    "        Args:\n",
    "            image_path: Ruta a la imagen o crop a analizar\n",
    "            use_cache: Usar cache para evitar re-clasificar\n",
    "            \n",
    "        Returns:\n",
    "            Dict con detected_type, confidence, reasoning\n",
    "        \"\"\"\n",
    "        # Verificar cache\n",
    "        if use_cache and image_path in self._classification_cache:\n",
    "            return self._classification_cache[image_path]\n",
    "        \n",
    "        # Cargar modelo si es necesario\n",
    "        if self.model is None:\n",
    "            self._load_model()\n",
    "        \n",
    "        # Si el modelo es mock, usar heurÃ­sticas\n",
    "        if self.model == \"mock\":\n",
    "            result = self._classify_mock(image_path)\n",
    "        else:\n",
    "            result = await self._classify_with_llm(image_path)\n",
    "        \n",
    "        # Guardar en cache\n",
    "        if use_cache:\n",
    "            self._classification_cache[image_path] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _classify_mock(self, image_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ClasificaciÃ³n mock basada en nombre de archivo para testing.\n",
    "        En producciÃ³n, esto serÃ­a reemplazado por anÃ¡lisis LLM real.\n",
    "        \"\"\"\n",
    "        path_lower = image_path.lower()\n",
    "        \n",
    "        if \"finger\" in path_lower or \"huella\" in path_lower:\n",
    "            return {\n",
    "                \"detected_type\": \"fingerprint\",\n",
    "                \"confidence\": 0.85,\n",
    "                \"reasoning\": \"Mock: Filename suggests fingerprint content\"\n",
    "            }\n",
    "        elif \"dni\" in path_lower or \"passport\" in path_lower or \"documento\" in path_lower:\n",
    "            return {\n",
    "                \"detected_type\": \"id_document\",\n",
    "                \"confidence\": 0.85,\n",
    "                \"reasoning\": \"Mock: Filename suggests ID document\"\n",
    "            }\n",
    "        elif \"card\" in path_lower or \"tarjeta\" in path_lower or \"visa\" in path_lower:\n",
    "            return {\n",
    "                \"detected_type\": \"credit_card\",\n",
    "                \"confidence\": 0.85,\n",
    "                \"reasoning\": \"Mock: Filename suggests credit card\"\n",
    "            }\n",
    "        elif \"firma\" in path_lower or \"signature\" in path_lower:\n",
    "            return {\n",
    "                \"detected_type\": \"signature\",\n",
    "                \"confidence\": 0.80,\n",
    "                \"reasoning\": \"Mock: Filename suggests signature\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"detected_type\": \"none\",\n",
    "            \"confidence\": 0.7,\n",
    "            \"reasoning\": \"Mock: No sensitive content detected in filename\"\n",
    "        }\n",
    "    \n",
    "    async def _classify_with_llm(self, image_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ClasificaciÃ³n real usando modelo de visiÃ³n-lenguaje.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from PIL import Image\n",
    "            import json\n",
    "            \n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            \n",
    "            # Preparar inputs para el modelo\n",
    "            inputs = self.processor(\n",
    "                text=SENSITIVE_CONTENT_CLASSIFICATION_PROMPT,\n",
    "                images=image,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            # Generar respuesta\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=200,\n",
    "                do_sample=False\n",
    "            )\n",
    "            \n",
    "            response = self.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            # Parsear JSON de la respuesta\n",
    "            json_start = response.find(\"{\")\n",
    "            json_end = response.rfind(\"}\") + 1\n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                return json.loads(response[json_start:json_end])\n",
    "            \n",
    "            return {\"detected_type\": \"none\", \"confidence\": 0.5, \"reasoning\": \"Could not parse LLM response\"}\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"LLM classification error: {e}\")\n",
    "            return {\"detected_type\": \"none\", \"confidence\": 0.3, \"reasoning\": f\"Error: {str(e)}\"}\n",
    "\n",
    "    async def analyze_image(\n",
    "        self, \n",
    "        image_path: str, \n",
    "        context: List[Dict[str, Any]], \n",
    "        detection_type: str\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analiza una imagen para determinar si hay violaciÃ³n GDPR.\n",
    "        Combina clasificaciÃ³n de contenido con anÃ¡lisis legal.\n",
    "        \"\"\"\n",
    "        # Si el tipo es \"unknown\" o \"hand\", intentar clasificar con LLM\n",
    "        if detection_type in (\"unknown\", \"hand\", \"hand_crop\"):\n",
    "            classification = await self.classify_sensitive_content(image_path)\n",
    "            if classification[\"detected_type\"] != \"none\":\n",
    "                detection_type = classification[\"detected_type\"]\n",
    "                logging.info(f\"LLM classified {image_path} as {detection_type}\")\n",
    "        \n",
    "        # Determinar violaciÃ³n basada en tipo\n",
    "        return self._determine_violation(detection_type, context)\n",
    "\n",
    "    def _determine_violation(self, detection_type: str, context: List[Dict]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Determina si hay violaciÃ³n basÃ¡ndose en el tipo de detecciÃ³n.\n",
    "        \n",
    "        LÃ³gica GDPR:\n",
    "        - Caras, huellas, documentos de identidad -> SIEMPRE violaciÃ³n\n",
    "        - MatrÃ­culas, tarjetas de crÃ©dito -> ViolaciÃ³n\n",
    "        - Personas -> Depende del contexto\n",
    "        \"\"\"\n",
    "        \n",
    "        # Tipos que SIEMPRE son violaciÃ³n bajo GDPR (Art. 9 - Datos especiales)\n",
    "        always_violation = {\"face\", \"fingerprint\", \"id_document\", \"credit_card\", \"hand_biometric\"}\n",
    "        \n",
    "        # Tipos que son violaciÃ³n con alta probabilidad\n",
    "        likely_violation = {\"license_plate\", \"signature\"}\n",
    "        \n",
    "        # Tipos que dependen del contexto\n",
    "        context_dependent = {\"person\"}\n",
    "        \n",
    "        is_violation = False\n",
    "        severity = \"none\"\n",
    "        confidence = 0.0\n",
    "        reasoning = \"\"\n",
    "        recommended_action = \"none\"\n",
    "        \n",
    "        if detection_type in always_violation:\n",
    "            is_violation = True\n",
    "            severity = \"high\"\n",
    "            confidence = 0.95\n",
    "            \n",
    "            if detection_type == \"fingerprint\":\n",
    "                reasoning = \"Huella dactilar detectada: Dato biomÃ©trico especial segÃºn Art. 9 GDPR. Requiere consentimiento explÃ­cito para su procesamiento.\"\n",
    "                recommended_action = \"pixelate\"\n",
    "            elif detection_type == \"id_document\":\n",
    "                reasoning = \"Documento de identidad detectado: Contiene datos personales identificativos. Procesamiento requiere base legal segÃºn Art. 6 GDPR.\"\n",
    "                recommended_action = \"blur\"\n",
    "            elif detection_type == \"credit_card\":\n",
    "                reasoning = \"Tarjeta bancaria detectada: Dato financiero sensible. Requiere medidas de seguridad segÃºn Art. 32 GDPR.\"\n",
    "                recommended_action = \"pixelate\"\n",
    "            elif detection_type == \"hand_biometric\":\n",
    "                reasoning = \"Mano con caracterÃ­sticas biomÃ©tricas: Puede usarse para identificaciÃ³n. Art. 9 GDPR aplica.\"\n",
    "                recommended_action = \"blur\"\n",
    "            else:  # face\n",
    "                reasoning = f\"DetecciÃ³n de {detection_type}: Dato biomÃ©trico segÃºn Art. 9 GDPR. Requiere consentimiento explÃ­cito.\"\n",
    "                recommended_action = \"blur\"\n",
    "            \n",
    "        elif detection_type in likely_violation:\n",
    "            is_violation = True\n",
    "            severity = \"high\"\n",
    "            confidence = 0.90\n",
    "            \n",
    "            if detection_type == \"signature\":\n",
    "                reasoning = \"Firma manuscrita detectada: Identificador personal Ãºnico. Art. 6 GDPR requiere base legal.\"\n",
    "                recommended_action = \"blur\"\n",
    "            else:  # license_plate\n",
    "                reasoning = f\"DetecciÃ³n de {detection_type}: Identificador personal que permite identificaciÃ³n indirecta segÃºn Art. 4 GDPR.\"\n",
    "                recommended_action = \"pixelate\"\n",
    "            \n",
    "        elif detection_type in context_dependent:\n",
    "            is_violation = True\n",
    "            severity = \"medium\"\n",
    "            confidence = 0.75\n",
    "            reasoning = f\"DetecciÃ³n de {detection_type}: Imagen personal que requiere base legal segÃºn Art. 6 GDPR. En espacios pÃºblicos, puede haber excepciones.\"\n",
    "            recommended_action = \"blur\"\n",
    "        \n",
    "        else:\n",
    "            is_violation = False\n",
    "            severity = \"none\"\n",
    "            confidence = 0.5\n",
    "            reasoning = f\"Tipo '{detection_type}' no clasificado como dato sensible GDPR.\"\n",
    "            recommended_action = \"none\"\n",
    "        \n",
    "        return {\n",
    "            \"is_violation\": is_violation,\n",
    "            \"severity\": severity,\n",
    "            \"violated_articles\": GDPR_ARTICLES.get(detection_type, [\"6\"]),\n",
    "            \"reasoning\": reasoning,\n",
    "            \"confidence\": confidence,\n",
    "            \"detection_type\": detection_type,\n",
    "            \"recommended_action\": recommended_action\n",
    "        }\n",
    "\n",
    "# Importar torch para verificaciÃ³n de CUDA\n",
    "import torch\n",
    "logging.info(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b154e29",
   "metadata": {},
   "source": [
    "### 4. Sistema Multi-Agente (`sub_agent.py`, `consensus_agent.py`)\n",
    "AquÃ­ estructuramos la decisiÃ³n:\n",
    "- **`SubAgent`**: Representa un experto individual. Usa el grafo para informarse y el LLM para decidir sobre UNA detecciÃ³n especÃ­fica.\n",
    "- **`ConsensusAgent`**: Recibe las opiniones de los sub-agentes (si tuviÃ©ramos varios analizando lo mismo) y toma la decisiÃ³n final. TambiÃ©n normaliza el formato de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34080bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubAgent:\n",
    "    def __init__(self, agent_id: str):\n",
    "        self.agent_id = agent_id\n",
    "        self.graph_client = GraphClient()\n",
    "        self.gemma_client = GemmaClient()\n",
    "        \n",
    "    async def verify(self, image_path: str, detection: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        detection_type = detection.get(\"detection_type\", \"unknown\")\n",
    "        context = await self.graph_client.get_context_for_detection(detection_type)\n",
    "        res = await self.gemma_client.analyze_image(image_path, context, detection_type)\n",
    "        res[\"agent_id\"] = self.agent_id\n",
    "        res[\"detection_id\"] = detection.get(\"id\")\n",
    "        return res\n",
    "\n",
    "class ConsensusAgent:\n",
    "    def aggregate(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        if not results: return {}\n",
    "        return self._validate(results[0])\n",
    "\n",
    "    def _validate(self, result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        defaults = {\"is_violation\": False, \"severity\": \"none\", \"confidence\": 0.0}\n",
    "        for k, v in defaults.items():\n",
    "            if k not in result: result[k] = v\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81c409",
   "metadata": {},
   "source": [
    "### 5. Procesador Paralelo (`parallel_processor.py`)\n",
    "Orquesta la ejecuciÃ³n masiva.\n",
    "- **`process_batch`**: Recibe una imagen y MUCHAS detecciones (ej. 10 personas en una foto).\n",
    "- Crea un `SubAgent` para cada detecciÃ³n.\n",
    "- Usa `asyncio.gather` para ejecutarlos todos a la vez (paralelismo), acelerando mucho el anÃ¡lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a594ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelProcessor:\n",
    "    def __init__(self):\n",
    "        self.consensus = ConsensusAgent()\n",
    "        \n",
    "    async def process_batch(self, image_path: str, detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        tasks = []\n",
    "        for det in detections:\n",
    "            tasks.append(self._process_single(image_path, det))\n",
    "        return await asyncio.gather(*tasks)\n",
    "        \n",
    "    async def _process_single(self, image_path: str, detection: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        agent = SubAgent(f\"agent-{detection.get('detection_type')}\")\n",
    "        res = await agent.verify(image_path, detection)\n",
    "        return self.consensus.aggregate([res])\n",
    "\n",
    "processor = ParallelProcessor()\n",
    "\n",
    "async def verify_image_detections(image_path: str, detections: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    return await processor.process_batch(image_path, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ee993",
   "metadata": {},
   "source": [
    "### 6. EjecuciÃ³n de Prueba\n",
    "Simulamos una lista de 2 detecciones y llamamos al orquestador para ver si detecta violaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not load LLM model: 'dict' object has no attribute 'llm_model'. Using mock responses.\n",
      "INFO:root:LLM classified crops/hand_huella_visible.jpg as fingerprint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: VerificaciÃ³n de Detecciones Conocidas segÃºn GDPR\n",
      "======================================================================\n",
      "Neo4j Error: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}\n",
      "Neo4j Error: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}\n",
      "Neo4j Error: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}\n",
      "Neo4j Error: {code: Neo.ClientError.Security.AuthenticationRateLimit} {message: The client has provided incorrect authentication details too many times in a row.}\n",
      "Neo4j Error: {code: Neo.ClientError.Security.AuthenticationRateLimit} {message: The client has provided incorrect authentication details too many times in a row.}\n",
      "Neo4j Error: {code: Neo.ClientError.Security.AuthenticationRateLimit} {message: The client has provided incorrect authentication details too many times in a row.}\n",
      "Neo4j Error: {code: Neo.ClientError.Security.AuthenticationRateLimit} {message: The client has provided incorrect authentication details too many times in a row.}\n",
      "\n",
      "Resultados de verificaciÃ³n:\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸ”´\n",
      "  Tipo: face\n",
      "  Severidad: high\n",
      "  Confianza: 95%\n",
      "  ArtÃ­culos GDPR: 9, 6\n",
      "  AcciÃ³n recomendada: blur\n",
      "  Razonamiento: DetecciÃ³n de face: Dato biomÃ©trico segÃºn Art. 9 GDPR. Requiere consentimiento ex...\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸ”´\n",
      "  Tipo: license_plate\n",
      "  Severidad: high\n",
      "  Confianza: 90%\n",
      "  ArtÃ­culos GDPR: 6, 17\n",
      "  AcciÃ³n recomendada: pixelate\n",
      "  Razonamiento: DetecciÃ³n de license_plate: Identificador personal que permite identificaciÃ³n in...\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸŸ¡\n",
      "  Tipo: person\n",
      "  Severidad: medium\n",
      "  Confianza: 75%\n",
      "  ArtÃ­culos GDPR: 6, 13\n",
      "  AcciÃ³n recomendada: blur\n",
      "  Razonamiento: DetecciÃ³n de person: Imagen personal que requiere base legal segÃºn Art. 6 GDPR. ...\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸ”´\n",
      "  Tipo: fingerprint\n",
      "  Severidad: high\n",
      "  Confianza: 95%\n",
      "  ArtÃ­culos GDPR: 9, 6\n",
      "  AcciÃ³n recomendada: pixelate\n",
      "  Razonamiento: Huella dactilar detectada: Dato biomÃ©trico especial segÃºn Art. 9 GDPR. Requiere ...\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸ”´\n",
      "  Tipo: id_document\n",
      "  Severidad: high\n",
      "  Confianza: 95%\n",
      "  ArtÃ­culos GDPR: 9, 6, 32\n",
      "  AcciÃ³n recomendada: blur\n",
      "  Razonamiento: Documento de identidad detectado: Contiene datos personales identificativos. Pro...\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸ”´\n",
      "  Tipo: credit_card\n",
      "  Severidad: high\n",
      "  Confianza: 95%\n",
      "  ArtÃ­culos GDPR: 6, 32\n",
      "  AcciÃ³n recomendada: pixelate\n",
      "  Razonamiento: Tarjeta bancaria detectada: Dato financiero sensible. Requiere medidas de seguri...\n",
      "\n",
      "âš ï¸ VIOLACIÃ“N ğŸ”´\n",
      "  Tipo: signature\n",
      "  Severidad: high\n",
      "  Confianza: 90%\n",
      "  ArtÃ­culos GDPR: 6\n",
      "  AcciÃ³n recomendada: blur\n",
      "  Razonamiento: Firma manuscrita detectada: Identificador personal Ãºnico. Art. 6 GDPR requiere b...\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "TEST 2: ClasificaciÃ³n LLM de Contenido Sensible\n",
      "======================================================================\n",
      "\n",
      "Este test simula la clasificaciÃ³n de crops de imagen por el LLM.\n",
      "En producciÃ³n, el LLM analizarÃ­a la imagen real.\n",
      "\n",
      "ğŸ” captures/track_1/huella_001.jpg\n",
      "    Tipo detectado: fingerprint\n",
      "    Confianza: 85%\n",
      "    RazÃ³n: Mock: Filename suggests fingerprint content\n",
      "\n",
      "ğŸ” captures/track_2/dni_front.jpg\n",
      "    Tipo detectado: id_document\n",
      "    Confianza: 85%\n",
      "    RazÃ³n: Mock: Filename suggests ID document\n",
      "\n",
      "ğŸ” captures/track_3/tarjeta_visa.jpg\n",
      "    Tipo detectado: credit_card\n",
      "    Confianza: 85%\n",
      "    RazÃ³n: Mock: Filename suggests credit card\n",
      "\n",
      "ğŸ” captures/track_4/firma_contrato.jpg\n",
      "    Tipo detectado: signature\n",
      "    Confianza: 80%\n",
      "    RazÃ³n: Mock: Filename suggests signature\n",
      "\n",
      "â– captures/track_5/mano_normal.jpg\n",
      "    Tipo detectado: none\n",
      "    Confianza: 70%\n",
      "    RazÃ³n: Mock: No sensitive content detected in filename\n",
      "\n",
      "\n",
      "\n",
      "======================================================================\n",
      "TEST 3: Flujo Completo - Hand Crop â†’ LLM â†’ GDPR Verification\n",
      "======================================================================\n",
      "\n",
      "Este test simula el flujo cuando YOLO detecta una mano y el\n",
      "LLM debe clasificar si contiene huella dactilar.\n",
      "\n",
      "Neo4j Error: {code: Neo.ClientError.Security.AuthenticationRateLimit} {message: The client has provided incorrect authentication details too many times in a row.}\n",
      "DetecciÃ³n original: hand\n",
      "  â†’ ClasificaciÃ³n final: fingerprint\n",
      "  â†’ ViolaciÃ³n: SÃ­\n",
      "  â†’ Severidad: high\n",
      "  â†’ AcciÃ³n: pixelate\n",
      "\n",
      "Neo4j Error: {code: Neo.ClientError.Security.AuthenticationRateLimit} {message: The client has provided incorrect authentication details too many times in a row.}\n",
      "DetecciÃ³n original: hand_crop\n",
      "  â†’ ClasificaciÃ³n final: hand_crop\n",
      "  â†’ ViolaciÃ³n: No\n",
      "  â†’ Severidad: none\n",
      "  â†’ AcciÃ³n: none\n",
      "\n",
      "======================================================================\n",
      "RESUMEN DE CAPACIDADES\n",
      "======================================================================\n",
      "\n",
      "Tipos de datos sensibles detectables:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Tipo            â”‚ Severidad  â”‚ ArtÃ­culos   â”‚ MÃ©todo de DetecciÃ³n     â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ face            â”‚ Alta       â”‚ 9, 6        â”‚ YOLO                    â”‚\n",
      "â”‚ fingerprint     â”‚ Alta       â”‚ 9, 6        â”‚ LLM (contexto de mano)  â”‚\n",
      "â”‚ license_plate   â”‚ Alta       â”‚ 6, 17       â”‚ YOLO                    â”‚\n",
      "â”‚ id_document     â”‚ Alta       â”‚ 9, 6, 32    â”‚ LLM                     â”‚\n",
      "â”‚ credit_card     â”‚ Alta       â”‚ 6, 32       â”‚ LLM                     â”‚\n",
      "â”‚ signature       â”‚ Media      â”‚ 6           â”‚ LLM                     â”‚\n",
      "â”‚ person          â”‚ Media      â”‚ 6, 13       â”‚ YOLO                    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRUEBA DE VERIFICACIÃ“N GDPR\n",
    "# =============================================================================\n",
    "\n",
    "# Test con diferentes tipos de detecciÃ³n GDPR\n",
    "detections_mock = [\n",
    "    {\"id\": \"1\", \"detection_type\": \"face\"},           # Alta severidad - BiomÃ©trico\n",
    "    {\"id\": \"2\", \"detection_type\": \"license_plate\"},  # Alta severidad - Identificador\n",
    "    {\"id\": \"3\", \"detection_type\": \"person\"},         # Media severidad - Contexto\n",
    "    {\"id\": \"4\", \"detection_type\": \"fingerprint\"},    # Alta severidad - BiomÃ©trico\n",
    "    {\"id\": \"5\", \"detection_type\": \"id_document\"},    # Alta severidad - Documento oficial\n",
    "    {\"id\": \"6\", \"detection_type\": \"credit_card\"},    # Alta severidad - Financiero\n",
    "    {\"id\": \"7\", \"detection_type\": \"signature\"},      # Media severidad - Identificador\n",
    "]\n",
    "\n",
    "async def test_verification():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TEST 1: VerificaciÃ³n de Detecciones Conocidas segÃºn GDPR\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = await verify_image_detections(\n",
    "        \"dummy_path.jpg\",\n",
    "        detections_mock\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResultados de verificaciÃ³n:\\n\")\n",
    "    for r in results:\n",
    "        status = \"âš ï¸ VIOLACIÃ“N\" if r.get(\"is_violation\") else \"âœ… OK\"\n",
    "        severity_icon = {\"high\": \"ğŸ”´\", \"medium\": \"ğŸŸ¡\", \"low\": \"ğŸŸ¢\", \"none\": \"âšª\"}.get(r.get(\"severity\", \"none\"), \"âšª\")\n",
    "        \n",
    "        print(f\"{status} {severity_icon}\")\n",
    "        print(f\"  Tipo: {r.get('detection_type', 'unknown')}\")\n",
    "        print(f\"  Severidad: {r.get('severity', 'none')}\")\n",
    "        print(f\"  Confianza: {r.get('confidence', 0):.0%}\")\n",
    "        print(f\"  ArtÃ­culos GDPR: {', '.join(r.get('violated_articles', []))}\")\n",
    "        print(f\"  AcciÃ³n recomendada: {r.get('recommended_action', 'none')}\")\n",
    "        print(f\"  Razonamiento: {r.get('reasoning', 'N/A')[:80]}...\")\n",
    "        print()\n",
    "\n",
    "async def test_llm_classification():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TEST 2: ClasificaciÃ³n LLM de Contenido Sensible\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nEste test simula la clasificaciÃ³n de crops de imagen por el LLM.\")\n",
    "    print(\"En producciÃ³n, el LLM analizarÃ­a la imagen real.\\n\")\n",
    "    \n",
    "    # Simular rutas de archivos que el mock clasificarÃ¡\n",
    "    test_paths = [\n",
    "        \"captures/track_1/huella_001.jpg\",      # â†’ fingerprint\n",
    "        \"captures/track_2/dni_front.jpg\",       # â†’ id_document\n",
    "        \"captures/track_3/tarjeta_visa.jpg\",    # â†’ credit_card\n",
    "        \"captures/track_4/firma_contrato.jpg\",  # â†’ signature\n",
    "        \"captures/track_5/mano_normal.jpg\",     # â†’ none\n",
    "    ]\n",
    "    \n",
    "    client = GemmaClient()\n",
    "    \n",
    "    for path in test_paths:\n",
    "        result = await client.classify_sensitive_content(path)\n",
    "        \n",
    "        detected = result.get(\"detected_type\", \"none\")\n",
    "        conf = result.get(\"confidence\", 0)\n",
    "        reason = result.get(\"reasoning\", \"\")\n",
    "        \n",
    "        icon = \"ğŸ”\" if detected != \"none\" else \"â–\"\n",
    "        print(f\"{icon} {path}\")\n",
    "        print(f\"    Tipo detectado: {detected}\")\n",
    "        print(f\"    Confianza: {conf:.0%}\")\n",
    "        print(f\"    RazÃ³n: {reason}\")\n",
    "        print()\n",
    "\n",
    "async def test_hand_crop_flow():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TEST 3: Flujo Completo - Hand Crop â†’ LLM â†’ GDPR Verification\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nEste test simula el flujo cuando YOLO detecta una mano y el\")\n",
    "    print(\"LLM debe clasificar si contiene huella dactilar.\\n\")\n",
    "    \n",
    "    # Simular detecciones de manos que el LLM debe reclasificar\n",
    "    hand_detections = [\n",
    "        {\"id\": \"h1\", \"detection_type\": \"hand\", \"image_path\": \"crops/hand_huella_visible.jpg\"},\n",
    "        {\"id\": \"h2\", \"detection_type\": \"hand_crop\", \"image_path\": \"crops/hand_normal.jpg\"},\n",
    "    ]\n",
    "    \n",
    "    client = GemmaClient()\n",
    "    processor = ParallelProcessor()\n",
    "    \n",
    "    for det in hand_detections:\n",
    "        # El flujo interno reclasifica si es \"hand\"\n",
    "        result = await processor._process_single(det[\"image_path\"], det)\n",
    "        \n",
    "        print(f\"DetecciÃ³n original: {det['detection_type']}\")\n",
    "        print(f\"  â†’ ClasificaciÃ³n final: {result.get('detection_type')}\")\n",
    "        print(f\"  â†’ ViolaciÃ³n: {'SÃ­' if result.get('is_violation') else 'No'}\")\n",
    "        print(f\"  â†’ Severidad: {result.get('severity')}\")\n",
    "        print(f\"  â†’ AcciÃ³n: {result.get('recommended_action')}\")\n",
    "        print()\n",
    "\n",
    "async def run_all_tests():\n",
    "    await test_verification()\n",
    "    print(\"\\n\")\n",
    "    await test_llm_classification()\n",
    "    print(\"\\n\")\n",
    "    await test_hand_crop_flow()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"RESUMEN DE CAPACIDADES\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\"\"\n",
    "Tipos de datos sensibles detectables:\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Tipo            â”‚ Severidad  â”‚ ArtÃ­culos   â”‚ MÃ©todo de DetecciÃ³n     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ face            â”‚ Alta       â”‚ 9, 6        â”‚ YOLO                    â”‚\n",
    "â”‚ fingerprint     â”‚ Alta       â”‚ 9, 6        â”‚ LLM (contexto de mano)  â”‚\n",
    "â”‚ license_plate   â”‚ Alta       â”‚ 6, 17       â”‚ YOLO                    â”‚\n",
    "â”‚ id_document     â”‚ Alta       â”‚ 9, 6, 32    â”‚ LLM                     â”‚\n",
    "â”‚ credit_card     â”‚ Alta       â”‚ 6, 32       â”‚ LLM                     â”‚\n",
    "â”‚ signature       â”‚ Media      â”‚ 6           â”‚ LLM                     â”‚\n",
    "â”‚ person          â”‚ Media      â”‚ 6, 13       â”‚ YOLO                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    \"\"\")\n",
    "\n",
    "asyncio.run(run_all_tests())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
